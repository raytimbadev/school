\documentclass[letterpaper,11pt]{article}

\title{Assignment \#3\\Advanced theory of computation -- COMP 531}
\author{Jacob Thomas Errington (260636023)}
\date{7 March 2016}

\usepackage[margin=2.0cm]{geometry}
\usepackage{amsmath,amssymb,amsthm}

\newtheorem{proposition}{Proposition}
\newtheorem{claim}{Claim}

\newcommand{\F}{\mathbb{F}}

\begin{document}

\maketitle

\section*{Special iterated addition}

\begin{proposition}
    The sum of $\log n$ $n$-bit numbers can be computed in $AC^0$.
\end{proposition}

\begin{proof}
    We will construct a circuit of polynomial size and constant depth to
    compute the sum.

    First, let $r = \sqrt {\log n}$. Consider the input numbers in groups of
    size $r$, further splitting the columns into groups of size $r$ as well.
    Hence the full input ``grid'' of digits is cut up into squares with side
    measure $r$. Hence, each square has $r^2 = \log n$ bits in it.

    Next, we construct a circuit that computes the sum of one square. The sum
    will have at most $r + \log r$ bits, and we can compute each bit by a
    brute force approach with size
    $$
    2^{r + \log r} \leq 2^{2r} = 2^{2 \sqrt {\log n}} \in O(2^{\log n}) = O(n)
    $$
    and depth $2$ as an $OR$ of $AND$s representing a lookup table. Since each
    bit requires $O(n)$ gates to be computed, and there are
    $O(r + \log r) \in O(n)$ bits to compute per square, and there are a
    polynomial number of squares, this section of the overall circuit
    contributes a polynomial number of gates to the final circuit.

    Next, for each row group, we concatenate (with some zero padding) the
    second, fourth, sixth, etc. squares into one long binary string and
    similarly concatenate the first, third, fifth, etc. squares into another
    long binary string. These two strings will each have at most $n + \log r$
    bits. These two numbers may be added by an $AC^0$ circuit, which will
    contribute a constant amount of depth and a polynomial amount gates to the
    overall circuit.

    At this stage in the circuit, each row group, of which there are
    $\frac{\log n}{r}$, has been collapsed into an
    $n + \log r + \log{(n + \log r)}$ bit number.
    This whole process is repeated a second time on these numbers to produce
    $\frac{\frac{\log n}{r}}{r} = \frac{\log n}{r^2} = 1$ number, which is the
    answer.
\end{proof}

\section*{Lower bound for integer multiplication}

\begin{proposition}
    The product of two $n$-bit integers cannot be computed in $AC^0$.
\end{proposition}

\begin{proof}
    By $AC^0$-reduction from $PARITY$.

    Denote by $n$ the length of the input and let $x = x_1 \cdots x_n$ denote
    the input string.  We will consider a padding of the input as follows.
    Between each bit of the input, insert $k$ zeroes to construct a string
    $x^\prime$. Consequently, $|x^\prime| = n + (n-1){k}$.

    (We will pick a value for $k$ later in our analysis.)

    Then, construct the string $\hat x$ where $|\hat x| = |x^\prime|$ and for
    all $i$, $\hat x_i = 1$ if and only if $x^\prime_i$ corresponds to an input
    bit rather than a padding bit.

    Let $p = x^\prime \times {\hat x} = p_1 p_2 \cdots$, where $p_1$ is the
    least significant bit of the product. From looking at the behaviour of the
    the grade-school multiplication algorithm, we notice that
    $$
    p_{n + (n-1)k} = PARITY(x_1, \cdots, x_n, c_{n + (n-1)k})
    $$
    were $c_i$ is the $i$th carry bit generated by the additions of the
    algorithm. This is because the grade school algorithm generates $n +
    (n-1)k$ numbers to sum up in its final step. In fact, only at most $n$ of
    these are nonzero, and the column corresponding to $p_{n + (n-1)k}$ in the
    final sum (after discounting any numbers which are zero) will consist of
    the sum of all bits in $x$, a possible carry, which is precisely $PARITY$
    of those things.

    \begin{claim}
        There exists $k$ such that $$c_{n + (n-1)k} = 0$$.
    \end{claim}

    \begin{proof}
        This follows essentially from the introduction of the padding bits.
        Consider the terms generated by the grade-school algorithm but cut past
        the $n + (n-2)k$ least significant bits. At most $n - 1$ of these
        terms will be nonzero, so this can be considered a sum of $n - 1$
        $(n + (n-2)k)$-bit numbers. This sum has size at most
        $\log{(n + (n-2)k)}$ overflow bits, so pick $k$ such that
        $\log{(n + (n-2)k)} \leq k$.
    \end{proof}

    Due to the claim, we can have enough padding so as to guarantee that the
    carry bit in the column $n + (n-1)k$ is always zero. Hence,
    $$
    p_{n + (n-1)k} = PARITY(x_1, \cdots, x_n)
    $$
    which completes the reduction.
\end{proof}

\section*{Matching the minimal circuit size for boolean functions}

\begin{proposition}
    Any $n$-input boolean function can be computed by a bounded fan-in circuit
    of size $O(\frac{2^n}{n})$.
\end{proposition}

\begin{proof}

\end{proof}

\section*{Upper bound for the size of a $PARITY/AND$ circuit}

\begin{proposition}
    For any circuit consisting of a layer of $PARITY$ gates feeding into an
    $AND$ gate, there exists a circuit of linear size computing the same
    function.
\end{proposition}

\begin{proof}
    From a proof that $PARITY \notin AC^0$, we know that if a ciruit has $n$
    inputs, then a $PARITY$ gate in that circuit at level $1$ corresponds to a
    linear equation in $\F_2^n$. Hence, several parity gates in parallel at
    level $1$ can be considered as a matrix in $\F_2^n$.

    From linear algebra, we know that a matrix's column rank is equal to its
    row rank. Since the circuit inputs correspond to the columns of the matrix,
    the rank of the matrix is $n$, and hence its dimension is $d \leq n$.

    Finally, all vector spaces of the same dimension are isomorphic, so there
    exists a $d \times d$ matrix that computes the same linear map as the
    original matrix.

    We can use the rows of the new matrix to decide how to wire up the $PARITY$
    gates in the new circuit, which will have linear size.
\end{proof}

\end{document}
