\documentclass[letterpaper,11pt]{article}

\author{Jacob Thomas Errington (260636023)}
\title{Assignment \#4\\Advanced theory of computation -- COMP 531}
\date{30 March 2016}

\usepackage[margin=2.0cm]{geometry}
\usepackage{amsmath,amssymb,amsthm}

\usepackage{algorithm,algorithmicx,algpseudocode}

\newtheorem{prop}{Proposition}
\newtheorem{thm}{Theorem}

\DeclareMathOperator{\PrOp}{Pr}
\DeclareMathOperator{\poly}{poly}
\DeclareMathOperator{\EOp}{\mathbb{E}}
\renewcommand{\Pr}[1]{\PrOp{\left[\text{#1}\right]}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\E}[1]{\EOp{\left[\text{#1}\right]}}

\begin{document}

\maketitle

\section{Graph matchings and the probabilistic method}

\begin{prop}
    If a graph $G = (V, E)$ contains a matching $M$, then there exists a
    subgraph $H$ of $G$ with at least $\frac{|E| + |M|}{2}$ edges.
\end{prop}

\begin{proof} By the probabilistic method.

    We build a bipartite graph with parts $A$ and $B$ as follows.
    \begin{enumerate}
        \item
            Collect all vertices from one side of the matching into part $A$;

        \item
            Collect all vertices from the other side of the matching into part
            $B$;

        \item
            Distribute the remaining vertices randomly among $A$ and $B$.
    \end{enumerate}

    Every edge that was not originally in $M$ has probability $\frac{1}{2}$ of
    being valid, i.e. such that its endpoints are in different sides of the
    bipartite graph. Hence,
    \begin{align*}
        \E{\# of ``legal'' edges}
        &= \Pr{an edge is valid} \cdot |\{\text{non matching edges}\}|
        + |\{\text{matching edges}\}| \\
        &= \frac{|E| - |M|}{2} + |M| \\
        &= \frac{|E| + |M|}{2}
    \end{align*}
    as required.
\end{proof}

\section{Upper bound on random bits}

\begin{prop}
    If for a problem $\{f_n\}$ we have a randomized protocol $P$ with
    \begin{equation*}
        \Pr{$P(x, y, r) \neq f_n(x, y)$} \leq \frac{1}{3}
    \end{equation*}
    then there exists a randomized protocol $Q$ using $|r| \in O(\log n)$
    random bits and still achieving an error rate of at most $\frac{1}{3}$.
\end{prop}

\begin{proof}
    By amplification, we first construct $\tilde P$ with error rate $\epsilon$
    (to be determined later). Let $\Pi$ consist of all the random sequences
    used by $\tilde P$ and let $p$ be the probability distribution of $\Pi$.
    Notice that $\tilde P$ is determined by $p$ and
    $\mathcal{P} = \{P_r | r \in \Pi\}$, where each $P_r$ is a deterministic
    protocol obtained by fixing the random string in a run of $\tilde P$.

    Next, define an error indicator
    \begin{equation*}
        z(x, y, r) = \begin{cases}
            1\quad \text{if}\, P_r(x,y) \neq f(x, y) \\
            0\quad \text{else}
        \end{cases}
    \end{equation*}

    Since $\tilde P$ computes f with error $\epsilon$, we have that for any
    $(x, y) \in X \times Y$,
    \begin{equation*}
        \mathbb{E}_{r\in\Pi}\left[z(x, y, r)\right]
        = \sum_{r\in\Pi}{p(r) \cdot z(x, y, r)} \leq \epsilon
    \end{equation*}

    Now we will show that there exists a set of $t$ deterministic protocols
    $\mathcal{Q} = \{Q_1, \ldots, Q_t\} \subseteq \mathcal{P}$ such
    that a uniform probability distribution $q$ over $\mathcal{Q}$
    (where $Q_i \mapsto \frac{1}{t}\,\forall i)$ will determine $Q$.

    To construct $\mathcal{Q}$, take $t$ arbitrary members of $\mathcal{P}$.
    Consider the randomized protocol $Q_{1,\ldots,t}$ determined by a uniform
    probability distribution $q$ over $\mathcal{Q}$.

    Then,
    \begin{align*}
        \mathbb{E}_q\left[z(x, y, r)\right]
        &= \sum_{i=1}^t {q(Q_i) \cdot z(x, y, r_i)} \\
        &= \sum_{i=1}^t {\frac{1}{t} z(x, y, r_i)}
    \end{align*}
    is the expected error of $Q_{1,\ldots,t}$.

    By the Chernoff bound, we have for any $(x, y) \in X \times Y$
    \begin{equation*}
        \PrOp_{1, \ldots, t}\left[
            \frac{1}{t}\sum_{i=1}^t {z(x, y, r_i)} - \epsilon > \epsilon
        \right]
        \leq
        2e^{-2\epsilon^2 t}
    \end{equation*}

    Now we choose $\epsilon$ and $t$ such that $\epsilon^2 t = n$, e.g.
    $\epsilon = \frac{1}{6}$ and $t = 36n$, so we get an upper bound of
    $2^{-2n}$ on the probability that the error rate is high on an input. Then
    by the union bound, we get that the probability that the error rate is high
    for at least one input (of which there are $2^{2n}$ possibilities) is
    \emph{less than} $1$.

    Thus, there exists a selection $r_1, \ldots, r_t$ such that for all $(x, y)
    \in X \times Y$ the error of the constructed protocol $Q_{1,\ldots,t}$ is
    at most $\frac{1}{3}$. Since $Q$ is uniformly distributed over the
    deterministic protocols $\mathcal{Q}$, the amount of random bits needed to
    run $Q$ is
    \begin{equation*}
        \log t = \log {36n} \leq 5 \log n \in O(\log n)
    \end{equation*}
    as required.
\end{proof}

\section{Communication complexity of disjointness}

\section{Cliques and independent sets}

A clique and an independent set either intersect at a single vertex or are
disjoint; this is a special case of the disjointness problem.

We propose the protocol given in algorithm $\ref{alg:clique-indep}$, in which
we name the players $\#1$ and $\#2$ and we suppose $\#1$ has the clique $C$ and
$\#2$ has the independent set $I$.

\begin{algorithm}
    \caption{Computes $|C \cap I|$}
    \begin{algorithmic}
        \If{$\exists v \in C$ such that $\deg v < \frac{n}{2}$}
            \State $\#1$ sends the name of such a $v$ to $\#2$
            \State $\#2$ sends whether $v \in I$
            \If{$v \in I$}
                \State the protocol ends, concluding $|C \cap I| = 0$
            \Else
                \State recurse on the subgraph determined by $v$ and its
                neighbours
            \EndIf
        \Else
            \State $\#1$ sends an empty message to $\#2$
        \EndIf

        \If{$\exists v \in I$ such that $\deg v \geq \frac{n}{2}$}
            \State $\#2$ sends the name of such a $v$ to $\#1$
            \State $\#1$ sends whether $v \in C$
            \If{$v \in C$}
                \State the protocol ends, concluding $|C \cap I| > 0$
            \Else
                \State recurse on the subgraph determined by $v$ and its
                non-neighbours
            \EndIf
        \Else
            $\#2$ ends the protocol and concludes that $|C \cap I| = 0$
        \EndIf
    \end{algorithmic}
    \label{alg:clique-indep}
\end{algorithm}

Each iteration uses $O(\log n)$ bits and there are $O(\log n)$ iterations due
to the cutting-by-half nature of the recursion, so the overall cost is
$O(\log^2 n)$.

\section{Randomized discrete logarithms}

\begin{prop}
    If an algorithm $A$ solves the discrete logarithm problem for
    $\frac{1}{\poly{n}}$ of the elements of $\Z_p^*$ for a prime $p$ in time
    $O(\poly n)$ where $n$ is the length of $p$, then there exists a randomized
    polytime algorithm that solves the discrete logarithm problem on all
    elements of the finite field with high probability.
\end{prop}

\begin{proof} By randomized self-reduction.

    Intuitively, if we pick an element $y \in \Z_p^*$ at random and give it to
    $A$, then $\Pr{$A$ finds $\log_g y$} = \frac{1}{\poly n}$. It
    suffices to find a way to turn a given $y$ into a random instance
    distributed uniformly over $\Z_p^*$.

    If $0 \leq t < p$ is chosen uniformly at random and $g^x = y$, then
    $g^{t+x} \equiv yg^t$ is independent of $y$ and also uniformly distributed
    over $\Z_p^*$. Thus,
    \begin{align*}
        \log_g y
            &\equiv \log_g{g^{x+t}} - t \\
            &\equiv \log_g{yg^t} - t
    \end{align*}
    so the problem is reduced to finding $\log_g{yg^t}$, which can now be done
    with probability $\frac{1}{\poly n}$.
\end{proof}

\end{document}
