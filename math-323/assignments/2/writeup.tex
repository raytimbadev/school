\documentclass[11pt,letterpaper]{article}

\author{Jacob Thomas Errington}
\title{Assignment \#2\\Probability -- MATH 323}
\date{24 February 2017}

\usepackage[margin=2.0cm]{geometry}
\usepackage{amsmath,amssymb,amsthm}

\renewcommand{\thesection}{Question \arabic{section}}
\newcommand{\question}{\section}

% misc math operators
\newcommand{\parens}[1]{\left(#1\right)}
\newcommand{\compose}{\circ}
\newcommand{\compl}[1]{\overline{#1}}

% Probabilistic operators
\DeclareMathOperator{\Prob}{P}
\renewcommand{\P}[1]{\Prob{\parens{#1}}}
\DeclareMathOperator{\prob}{p}
\newcommand{\p}[2][]{%
    \def\temp{#2}
    \ifx\temp\empty
        \prob{\parens{#2}}
    \else
        \prob_{#1}{\parens{#2}}
    \fi
}
\DeclareMathOperator{\Expect}{\mathbb{E}}
\newcommand{\E}[1]{\Expect{\left[#1\right]}}
\DeclareMathOperator{\Var}{\mathbb{V}}
\newcommand{\V}[1]{\Var{\parens{#1}}}
\DeclareMathOperator{\GeoOp}{Geo}
\newcommand{\Geo}[2]{\GeoOp{\parens{#1,#2}}}
\DeclareMathOperator{\BinOp}{Bin}
\newcommand{\Bin}[2]{\BinOp{\parens{#1,#2}}}

\begin{document}

\maketitle

\question{Online chess}

Jim plays chess online until he wins one game. He wins $\frac{100}{n}$ dollars
for winning in the $n$\textsuperscript{th} game. Each game is won with
probability $p$ and game outcomes are independent. Let $X$ be the random
variable representing Jim's winnings.

\begin{enumerate}
    \item
        To find the probability mass function of $X$, first notice that the
        sample space is the natural numbers, where each $n$ identifies the
        outcome ``the first game Jim wins is game $n$''.

        For the first game won to be game $n$ means to have lost game $i$ for
        all $i < n$. By independence, we can just multiply all the
        probabilities of these outcomes, giving
        \begin{equation*}
            \P{\text{lose game $1$ to $n-1$ and win game $n$}}
            = \P{\neg \text{win game}}^{n-1} \P{\text{win game}}
            = (1 - p)^{n-1} p
        \end{equation*}

        Hence, the probability mass function for $X$ is
        \begin{equation}
            \label{eq:pmf-x-1}
            \p{\frac{100}{n}} = (1-p)^{n-1} p
        \end{equation}

    \item
        To find the expectation, we can introduce a random variable $Y$ to
        denote the number of games that need to be played before Jim wins. This
        variable follows a geometric distribution.
        Then, let $f(x) = \frac{100}{x}$. This means we can rephrase the random
        variable $X = f \compose Y$.

\end{enumerate}

\question{Checking machines for malfunctions}

\begin{enumerate}
    \item
        Let $X$ be the random variable representing the number of functioning
        components in a machine.
        This quantity is binomially distributed; we have $X \sim \Bin{m}{p}$.
        A machine works correctly when $X = m$ or $X = m-1$. Hence, the
        probability of a machine correctly functioning is
        \begin{equation*}
            P_M = \P{X = m} + \P{X = m-1} = p^m \times p^{m-1}(1-p)
        \end{equation*}

        The probability of malfunction is $\compl{P_M} = 1 - P_M$.

        The number of inspected machines upon discovering that one is
        malfunctioning follows a geometric distribution with parameter
        $\compl{P_M}$.
        Let $Y$ be the random variable representing this quantity.

        Then, the probability that at least $k$ machines must be inspected
        before finding a malfunctioning one is precisely
        \begin{align*}
            \P{Y = k}
            &= (1 - \compl{P_M})^{k-1} \compl{P_M} \\
            &= \parens{1 - (1 - p^m p^{m-1}(1-p))}^{k-1}
                (1 - p^m p^{m-1}(1-p)) \\
            &= \parens{p^m p^{m-1} (1-p)}^{k-1} (1 - p^m p^{m-1}(1-p))
        \end{align*}
\end{enumerate}

\end{document}
